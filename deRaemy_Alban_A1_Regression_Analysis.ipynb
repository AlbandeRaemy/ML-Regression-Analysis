{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "Individual Case\n",
    "\n",
    "Alban de Raemy\n",
    "\n",
    "Regression Analysis\n",
    "\n",
    "MSBA 2\n",
    "\n",
    "Machine Learning\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Purpose of this Script</h2><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script's purpose is to build a predictive model on the continuous variable (Revenue). The goal is to develop reliable models, compare them and select the best model to predict revenue from a customer in their first year of using Apprentice Chef.\n",
    "My personal goal is to develop my skills in creating predictive models in python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Analytical Objectives</h2><br>\n",
    "\n",
    "Part 1:\n",
    "Understand how much revenue Apprentice Chef should expect from each customer within their first year of using the services.\n",
    "\n",
    "Part 2: Predict which customer will subscribe to the Halfway there service.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Fundamental Data Exploration</h2><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd                                  # data science essentials\n",
    "import matplotlib.pyplot as plt                      # essential graphical output\n",
    "import seaborn as sns                                # enhanced graphical output\n",
    "from   scipy import stats                            # stats essentials\n",
    "import statsmodels.formula.api as smf                # predictive modeling with nice outputs\n",
    "import gender_guesser.detector as gender             # guess gender based on (given) name\n",
    "import random as rand                                # random\n",
    "import statsmodels.formula.api as smf                # regression modeling\n",
    "from sklearn.model_selection import train_test_split # train/test split\n",
    "from sklearn.linear_model import LinearRegression    # Linear Regression  \n",
    "from sklearn.neighbors import KNeighborsRegressor    # KNN for Regression\n",
    "from sklearn.preprocessing import StandardScaler     # standard scaler\n",
    "import sklearn.linear_model                          # Linear Regression\n",
    "from itertools import combinations                   # combinations of features\n",
    "\n",
    "\n",
    "# setting pandas print options\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# setting random seed\n",
    "rand.seed(a = 219)\n",
    "\n",
    "# specifying file name\n",
    "file = './Apprentice_Chef_Dataset.xlsx'\n",
    "\n",
    "\n",
    "# reading the file into Python\n",
    "chef = pd.read_excel(io=file)\n",
    "\n",
    "\n",
    "# using .shape to view (ROWS, COLUMNS)\n",
    "chef.shape\n",
    "\n",
    "# formatting and printing the dimensions of the dataset\n",
    "#print(f\"\"\"\n",
    "#Size of Original Dataset\n",
    "#------------------------\n",
    "#Observations: {chef.shape[0]}\n",
    "#Features:     {chef.shape[1]}\n",
    "#\"\"\")\n",
    "\n",
    "# Un-comment the follwing lines for in-deepth analysis\n",
    "#print(chef.columns)\n",
    "#chef.head(n=5)\n",
    "#chef.info() \n",
    "# As we can see there is no null variables\n",
    "\n",
    "# rename LARGEST_ORDER_SIZE to AVG_MEALS_ORDERED\n",
    "chef.rename(columns={'LARGEST_ORDER_SIZE': 'AVG_MEALS_ORDERED'}, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Our y-variable is REVENUE\n",
    "#sns.displot(data = chef,\n",
    "#           x = \"REVENUE\",\n",
    "#           height = 5,\n",
    "#           aspect = 2)\n",
    "# displaying the histogram\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start our analysis with 1946 Observations and 28 Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Missing Value Analysis and Imputation</h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "#checking if there is any missing data\n",
    "#chef.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are only missing values in the family name variable (47 of them). We don't need to\n",
    "imput those missing values because they are irrelevant to our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Classify Data</h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REVENUE</th>\n",
       "      <th>CROSS_SELL_SUCCESS</th>\n",
       "      <th>TOTAL_MEALS_ORDERED</th>\n",
       "      <th>UNIQUE_MEALS_PURCH</th>\n",
       "      <th>CONTACTS_W_CUSTOMER_SERVICE</th>\n",
       "      <th>PRODUCT_CATEGORIES_VIEWED</th>\n",
       "      <th>AVG_TIME_PER_SITE_VISIT</th>\n",
       "      <th>MOBILE_NUMBER</th>\n",
       "      <th>CANCELLATIONS_BEFORE_NOON</th>\n",
       "      <th>CANCELLATIONS_AFTER_NOON</th>\n",
       "      <th>TASTES_AND_PREFERENCES</th>\n",
       "      <th>PC_LOGINS</th>\n",
       "      <th>MOBILE_LOGINS</th>\n",
       "      <th>WEEKLY_PLAN</th>\n",
       "      <th>EARLY_DELIVERIES</th>\n",
       "      <th>LATE_DELIVERIES</th>\n",
       "      <th>PACKAGE_LOCKER</th>\n",
       "      <th>REFRIGERATED_LOCKER</th>\n",
       "      <th>AVG_PREP_VID_TIME</th>\n",
       "      <th>AVG_MEALS_ORDERED</th>\n",
       "      <th>MASTER_CLASSES_ATTENDED</th>\n",
       "      <th>MEDIAN_MEAL_RATING</th>\n",
       "      <th>AVG_CLICKS_PER_VISIT</th>\n",
       "      <th>TOTAL_PHOTOS_VIEWED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2107.29</td>\n",
       "      <td>0.68</td>\n",
       "      <td>74.63</td>\n",
       "      <td>4.9</td>\n",
       "      <td>6.98</td>\n",
       "      <td>5.38</td>\n",
       "      <td>99.60</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.71</td>\n",
       "      <td>5.52</td>\n",
       "      <td>1.48</td>\n",
       "      <td>11.33</td>\n",
       "      <td>1.49</td>\n",
       "      <td>2.97</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.11</td>\n",
       "      <td>150.56</td>\n",
       "      <td>4.44</td>\n",
       "      <td>0.60</td>\n",
       "      <td>2.79</td>\n",
       "      <td>13.51</td>\n",
       "      <td>106.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1138.29</td>\n",
       "      <td>0.47</td>\n",
       "      <td>55.31</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.28</td>\n",
       "      <td>3.04</td>\n",
       "      <td>62.34</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.53</td>\n",
       "      <td>13.57</td>\n",
       "      <td>2.32</td>\n",
       "      <td>2.74</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.32</td>\n",
       "      <td>49.45</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.76</td>\n",
       "      <td>2.33</td>\n",
       "      <td>181.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>131.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>10.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.40</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1350.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>39.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>72.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>114.40</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1740.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>60.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>94.16</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>145.60</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2670.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>95.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>117.29</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>173.78</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>174.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8793.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>493.00</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1645.60</td>\n",
       "      <td>1.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>52.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>19.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>564.20</td>\n",
       "      <td>11.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>19.00</td>\n",
       "      <td>1600.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       REVENUE  CROSS_SELL_SUCCESS  TOTAL_MEALS_ORDERED  UNIQUE_MEALS_PURCH  CONTACTS_W_CUSTOMER_SERVICE  PRODUCT_CATEGORIES_VIEWED  AVG_TIME_PER_SITE_VISIT  MOBILE_NUMBER  CANCELLATIONS_BEFORE_NOON  CANCELLATIONS_AFTER_NOON  TASTES_AND_PREFERENCES  PC_LOGINS  MOBILE_LOGINS  WEEKLY_PLAN  EARLY_DELIVERIES  LATE_DELIVERIES  PACKAGE_LOCKER  REFRIGERATED_LOCKER  AVG_PREP_VID_TIME  AVG_MEALS_ORDERED  MASTER_CLASSES_ATTENDED  MEDIAN_MEAL_RATING  AVG_CLICKS_PER_VISIT  TOTAL_PHOTOS_VIEWED\n",
       "count  1946.00             1946.00              1946.00              1946.0                      1946.00                    1946.00                  1946.00        1946.00                    1946.00                   1946.00                 1946.00    1946.00        1946.00      1946.00           1946.00          1946.00         1946.00              1946.00            1946.00            1946.00                  1946.00             1946.00               1946.00              1946.00\n",
       "mean   2107.29                0.68                74.63                 4.9                         6.98                       5.38                    99.60           0.88                       1.40                      0.17                    0.71       5.52           1.48        11.33              1.49             2.97            0.36                 0.11             150.56               4.44                     0.60                2.79                 13.51               106.43\n",
       "std    1138.29                0.47                55.31                 2.5                         2.28                       3.04                    62.34           0.33                       1.55                      0.43                    0.45       0.58           0.53        13.57              2.32             2.74            0.48                 0.32              49.45               1.55                     0.64                0.76                  2.33               181.01\n",
       "min     131.00                0.00                11.00                 1.0                         1.00                       1.00                    10.33           0.00                       0.00                      0.00                    0.00       4.00           0.00         0.00              0.00             0.00            0.00                 0.00              33.40               1.00                     0.00                1.00                  5.00                 0.00\n",
       "25%    1350.00                0.00                39.00                 3.0                         5.00                       3.00                    72.00           1.00                       0.00                      0.00                    0.00       5.00           1.00         1.00              0.00             1.00            0.00                 0.00             114.40               3.00                     0.00                2.00                 12.00                 0.00\n",
       "50%    1740.00                1.00                60.00                 5.0                         7.00                       5.00                    94.16           1.00                       1.00                      0.00                    1.00       6.00           1.00         7.00              0.00             2.00            0.00                 0.00             145.60               4.00                     1.00                3.00                 13.00                 0.00\n",
       "75%    2670.00                1.00                95.00                 7.0                         8.00                       8.00                   117.29           1.00                       2.00                      0.00                    1.00       6.00           2.00        13.00              3.00             4.00            1.00                 0.00             173.78               5.00                     1.00                3.00                 15.00               174.00\n",
       "max    8793.75                1.00               493.00                19.0                        18.00                      10.00                  1645.60           1.00                      13.00                      3.00                    1.00       7.00           3.00        52.00              9.00            19.00            1.00                 1.00             564.20              11.00                     3.00                5.00                 19.00              1600.00"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# descriptive statistics for numeric data\n",
    "chef.describe(include='number').round(2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "CONTINUOUS\n",
    "----------\n",
    "REVENUE\n",
    "AVG_TIME_PER_SITE_VISIT\t\n",
    "WEEKLY_PLAN\t(Number of weeks the customer subscribed to weekly plan)\n",
    "AVG_PREP_VID_TIME (avg. time in second meal prep instruction video was playing)\n",
    "AVG_MEALS_ORDERED (Avg_number of meals ordered by customer)\n",
    "AVG_CLICKS_PER_VISIT\n",
    "TOTAL_PHOTOS_VIEWED\n",
    "\n",
    "\n",
    "INTERVAL / COUNT\n",
    "----------------\n",
    "TOTAL_MEALS_ORDERED\n",
    "AVG_MEALS_ORDERED\n",
    "MEDIAN_MEAL_RATING\n",
    "UNIQUE_MEALS_PURCH\n",
    "CONTACTS_W_CUSTOMER_SERVICE\n",
    "PRODUCT_CATEGORIES_VIEWED\n",
    "CANCELLATIONS_BEFORE_NOON\n",
    "CANCELLATIONS_AFTER_NOON\n",
    "PC_LOGINS\n",
    "MOBILE_LOGINS\n",
    "EARLY_DELIVERIES\n",
    "LATE_DELIVERIES\t\n",
    "MASTER_CLASSES_ATTENDED\n",
    "\n",
    "\n",
    "CATEGORICAL\n",
    "-----------\n",
    "MOBILE_NUMBER (1= mobile, 0 = landline)\n",
    "PACKAGE_LOCKER\n",
    "REFRIGERATED_LOCKER\t\n",
    "CROSS_SELL_SUCCESS\n",
    "TASTES_AND_PREFERENCES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Visual Data Exploration</h3><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created histograms and boxplots for each features to explore their distribution visually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# modify text\n",
    "# subsetting data so that the there's into categorical/descriptive data\n",
    "chef_num = chef.drop([\"NAME\", \"EMAIL\", \"FIRST_NAME\", \"FAMILY_NAME\"], axis = 1)\n",
    "chef_cat = chef.select_dtypes(include = 'object')\n",
    "\n",
    "\n",
    "# Look at histogram of the numerical variables to better understand their distribution\n",
    "#for i in chef_num.columns:\n",
    "#    def plot(x, y, z):\n",
    "#        fig, ax = plt.subplots(figsize = (12,12))\n",
    "#        plt.subplot(2,2,y)\n",
    "#        sns.distplot(chef[x],\n",
    "#            color = z)\n",
    "#        plt.xlabel(x)\n",
    "#        plt.title(x)\n",
    "#        plt.show()\n",
    "#        return\n",
    "#    plot(i, 1, \"b\")\n",
    "\n",
    "\n",
    "# Look at boxplot of numerical variables to better understand their distribution\n",
    "# sns.boxplot(x=chef['AVG_PREP_VID_TIME'])\n",
    "\n",
    "# creating a list of continuous features (including REVENUE)\n",
    "#continuous_data = ['REVENUE','AVG_TIME_PER_SITE_VISIT', 'WEEKLY_PLAN', 'AVG_PREP_VID_TIME',\n",
    "#                   'AVG_MEALS_ORDERED', 'AVG_CLICKS_PER_VISIT', 'TOTAL_PHOTOS_VIEWED']\n",
    "\n",
    "\n",
    "# developing a correlation matrix based on continuous features\n",
    "#chef_corr = chef[continuous_data].corr(method = 'pearson')\n",
    "\n",
    "\n",
    "# filtering the results to only show correlations with Sale_Price\n",
    "#chef_corr.loc[ : , 'REVENUE'].round(decimals = 2).sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tested the correlation with the continuous features we found. As of now, the highest correlation value her, was AVG_PREP_VID_TIME and TOTAL_PHOTOS_VIEWED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data Transformation</h2><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Outlier Startegy</h3><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# After exploring data distribution with scatterplots and boxplots, I've noticed outliers\n",
    "# Outlier detection and strategy\n",
    "\n",
    "# create a df where values with an absolute Z-score higher than 3 (outliers)\n",
    "outlier_df = pd.DataFrame(np.abs(stats.zscore(chef_num)) > 3, columns=chef_num.columns)\n",
    "outlier_columns = outlier_df.sum(axis=0).loc[(outlier_df.sum(axis=0) > 0)].index\n",
    "\n",
    "#create additional columns with the outliers for each variables, with out_ as prefix\n",
    "outlier_features = outlier_df[outlier_columns].astype('int').add_prefix('out_')\n",
    "chef_num = chef_num.join(outlier_features) #join the new columns to our chef_num df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I started by looking at histograms and boxplots of all numerical variables to have a better understanding of their\n",
    "distribution.\n",
    "I used the Z-score method to detect and highlight outliers. I created new columns for each variables and their outliers. I then highlighted in my dummy variables which values had an absolute Z-score higer than 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Log Transformation</h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "log_chef_col = ['REVENUE',\n",
    "                'AVG_TIME_PER_SITE_VISIT',\n",
    "                'WEEKLY_PLAN',\n",
    "                'AVG_PREP_VID_TIME',\n",
    "                'AVG_MEALS_ORDERED',\n",
    "                'AVG_CLICKS_PER_VISIT',\n",
    "                'TOTAL_PHOTOS_VIEWED',\n",
    "                'TOTAL_MEALS_ORDERED',\n",
    "                'AVG_MEALS_ORDERED',\n",
    "                'MEDIAN_MEAL_RATING',\n",
    "                'UNIQUE_MEALS_PURCH',\n",
    "                'CONTACTS_W_CUSTOMER_SERVICE',\n",
    "                'PRODUCT_CATEGORIES_VIEWED',\n",
    "                'CANCELLATIONS_BEFORE_NOON',\n",
    "                'CANCELLATIONS_AFTER_NOON',\n",
    "                'PC_LOGINS',\n",
    "                'MOBILE_LOGINS',\n",
    "                'EARLY_DELIVERIES',\n",
    "                'LATE_DELIVERIES',\n",
    "                'MASTER_CLASSES_ATTENDED',\n",
    "               ]\n",
    "# for loop to create new columns with the log transformation\n",
    "for col in log_chef_col:\n",
    "    chef_num['log_'+col] = np.log(chef_num[col]+1) #add 1 to avoid doing log of 0\n",
    "    \n",
    "# removing original columns now that we have the log columns\n",
    "chef_num.drop(log_chef_col, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used log transformation method that creates distribution easier to work with and more normally\n",
    "distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "After exploring the distribution visually of our new log variables with the help of scatter plots and box plots,\n",
    "we noticed that the variable log_TOTAL_PHOTOS_VIEWED still had a clear separation of customer who viewed \n",
    "photos and customer who didn't. For that reason, I decided to separate them with a dummy variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                             No\t\tYes\n",
      "                           ---------------------\n",
      "Total Photos Viewed       | 1140\t\t806\n",
      "Total Meals Ordered       | 0\t\t1946\n",
      "Avg Time per visit        | 0\t\t1946\n",
      "Unique meals purchased    | 0\t\t1946\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PHOTOS_VIEWED_zeros = len(chef_num['log_TOTAL_PHOTOS_VIEWED'][chef_num['log_TOTAL_PHOTOS_VIEWED'] == 0])\n",
    "TOTAL_MEALS_zeros = len(chef_num['log_TOTAL_MEALS_ORDERED'][chef_num['log_TOTAL_MEALS_ORDERED'] == 0])\n",
    "TIME_SPENT_zeros = len(chef_num['log_AVG_TIME_PER_SITE_VISIT'][chef_num['log_AVG_TIME_PER_SITE_VISIT'] == 0])\n",
    "\n",
    "#NOT CONTINUOUS MIGHT NEED TO CHANGE TECHNIQUE\n",
    "UNIQUE_MEALS_zeros = len(chef_num['log_UNIQUE_MEALS_PURCH'][chef_num['log_UNIQUE_MEALS_PURCH'] == 0])\n",
    "\n",
    "print(f\"\"\"\n",
    "                             No\\t\\tYes\n",
    "                           ---------------------\n",
    "Total Photos Viewed       | {PHOTOS_VIEWED_zeros}\\t\\t{len(chef) - PHOTOS_VIEWED_zeros}\n",
    "Total Meals Ordered       | {TOTAL_MEALS_zeros}\\t\\t{len(chef) - TOTAL_MEALS_zeros}\n",
    "Avg Time per visit        | {TIME_SPENT_zeros}\\t\\t{len(chef) - TIME_SPENT_zeros}\n",
    "Unique meals purchased    | {UNIQUE_MEALS_zeros}\\t\\t{len(chef) - UNIQUE_MEALS_zeros}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the chart, only Total Photos Viewed has a significant amount of \n",
    "values in the \"No\" column. I will separate both values in a dummy variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "#dummy variable for viewing photos\n",
    "chef_num['VIEWED_PHOTOS'] = 0\n",
    "\n",
    "for index, value in chef_num.iterrows():\n",
    "    \n",
    "    if chef_num.loc[index, 'log_TOTAL_PHOTOS_VIEWED'] >0:\n",
    "        chef_num.loc[index, 'VIEWED_PHOTOS'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Categorize Email</h3><br> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, the goal is to categorize the email domain in different groups. We start by separating the domain from the rest of the email address. We then create lists to separate the domains. We finish by creating dummy variables for each group of emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# STEP 1: splitting personal emails\n",
    "\n",
    "# placeholder list\n",
    "placeholder_lst = []\n",
    "\n",
    "# looping over each email address\n",
    "for index, col in chef_cat.iterrows():\n",
    "    \n",
    "    # splitting email domain at '@'\n",
    "    split_email = chef_cat.loc[index, 'EMAIL'].split(sep = '@')\n",
    "    \n",
    "    # appending placeholder_lst with the results\n",
    "    placeholder_lst.append(split_email)\n",
    "    \n",
    "\n",
    "# converting placeholder_lst into a DataFrame \n",
    "email_df = pd.DataFrame(placeholder_lst)\n",
    "\n",
    "\n",
    "# STEP 2: concatenating with original DataFrame\n",
    "\n",
    "# safety measure in case of multiple concatenations\n",
    "# remove? chef = pd.read_excel(file)\n",
    "\n",
    "\n",
    "# renaming column to concatenate\n",
    "email_df.columns = ['0' , 'personal_email_domain']\n",
    "\n",
    "\n",
    "# concatenating personal_email_domain with chef DataFrame\n",
    "chef_cat = pd.concat([chef_cat, email_df['personal_email_domain']],\n",
    "                   axis = 1)\n",
    "\n",
    "# set email domain types\n",
    "professional_email_domains = ['@mmm.com', '@amex.com', '@apple.com',\n",
    "                                '@boeing.com', '@caterpillar.com', '@chevron.com',\n",
    "                                '@cisco.com', '@cocacola.com', '@disney.com', \n",
    "                                '@dupont.com', '@exxon.com', '@ge.org', '@goldmansacs.com',\n",
    "                                '@homedepot.com', '@ibm.com', '@intel.com', '@jnj.com', \n",
    "                                '@jpmorgan.com','@mcdonalds.com', '@merck.com', '@microsoft.com',\n",
    "                                '@nike.com', '@pfizer.com', '@pg.com', '@travelers.com',\n",
    "                                '@unitedtech.com', '@unitedhealth.com', '@verizon.com', \n",
    "                                '@visa.com', '@walmart.com']\n",
    "junk_email_domains = ['@me.com', '@aol.com', '@hotmail.com', '@live.com', '@msn.com', '@passport.com']\n",
    "personal_email_domains  = ['@gmail.com', '@yahoo.com', '@protonmail.com']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# placeholder list\n",
    "placeholder_lst = []\n",
    "\n",
    "\n",
    "# looping to group observations by domain type\n",
    "for domain in email_df['personal_email_domain']:\n",
    "        if '@' + domain in professional_email_domains:\n",
    "            placeholder_lst.append('Professional')\n",
    "            \n",
    "        elif '@' + domain in personal_email_domains:\n",
    "            placeholder_lst.append('Personal')\n",
    "            \n",
    "        elif '@' + domain in junk_email_domains:\n",
    "            placeholder_lst.append('Junk')\n",
    "            \n",
    "        else:\n",
    "            placeholder_lst.append('Unknown')\n",
    "\n",
    "\n",
    "# concatenating with original DataFrame\n",
    "chef_cat['domain_group'] = pd.Series(placeholder_lst)\n",
    "\n",
    "\n",
    "# checking results\n",
    "# chef_cat['domain_group'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the emails fall into these 3 categories which make it easier to analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "\n",
    "########\n",
    "#creating a bool variable for each domain type\n",
    "########\n",
    "\n",
    "#creating a placeholder list that will be used by the following three loops\n",
    "plc_holder_list_pers = []\n",
    "plc_holder_list_prof = []\n",
    "plc_holder_list_junk = []\n",
    "\n",
    "\n",
    "#creating a variable \"Personal_Domain\" for personal email\n",
    "for i in chef_cat[\"domain_group\"]:\n",
    "    if i == \"Personal\":\n",
    "        plc_holder_list_pers.append(1)\n",
    "    else: \n",
    "        plc_holder_list_pers.append(0)\n",
    "        \n",
    "chef_cat[\"Personal_Domain\"] = pd.Series(plc_holder_list_pers)\n",
    "\n",
    "#creating a variable \"Professional_Domain\" for professional email\n",
    "for i in chef_cat[\"domain_group\"]:\n",
    "    if i == \"Professional\":\n",
    "        plc_holder_list_prof.append(1)\n",
    "    else:\n",
    "        plc_holder_list_prof.append(0)\n",
    "        \n",
    "chef_cat[\"Professional_Domain\"] = pd.Series(plc_holder_list_prof)\n",
    "\n",
    "#creating a variable \"Junk_Domain\" for Junk email\n",
    "for i in chef_cat[\"domain_group\"]:\n",
    "    if i == \"Junk\":\n",
    "        plc_holder_list_junk.append(1)\n",
    "    else:\n",
    "        plc_holder_list_junk.append(0)\n",
    "        \n",
    "chef_cat[\"Junk\"] = pd.Series(plc_holder_list_junk)\n",
    "\n",
    "#dropping un-needed columns\n",
    "chef_cat = chef_cat.drop([\"NAME\", \"EMAIL\", \"FAMILY_NAME\", \"domain_group\", \"personal_email_domain\"],\n",
    "             axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Gender Guesser</h3><br> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After observing that close to 70% of the gender where unknown even after manually modifying\n",
    "the name that appears multiple times so they get read correctly, we still get a poor results.\n",
    "Additionlay, the gender.guesser takes a very long time to process so I saved the result in a csv file\n",
    "but it adds considerable time for python to read it. \n",
    "For these reasons, I decided to drop the analysis of this variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Feature Engineering</h2><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# cleaning datasets from unnecessary features\n",
    "chef_model = chef_cat.join(chef_num)\n",
    "\n",
    "# drop revenue and strings variables\n",
    "chef_var = chef_model.drop([\"log_REVENUE\", \"FIRST_NAME\"], axis = 1)\n",
    "chef_model = chef_model.drop([\"FIRST_NAME\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Add additional interesting features</h3><br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Total Photos viewed per login (pc + mobile)\n",
    "chef_var['PHOTOS_VIEWED_PER_LOGIN'] = chef_var['log_TOTAL_PHOTOS_VIEWED'] / (chef_var['log_MOBILE_LOGINS'] + chef_var['log_PC_LOGINS'])\n",
    "chef_model['PHOTOS_VIEWED_PER_LOGIN'] = chef_model['log_TOTAL_PHOTOS_VIEWED'] / (chef_model['log_MOBILE_LOGINS'] + chef_model['log_PC_LOGINS'])\n",
    "\n",
    "# Mater class attended per avg prep vid time\n",
    "chef_var['NUMN_CLASS_PER_PREP_TIME'] = chef_var['log_MASTER_CLASSES_ATTENDED'] / chef_var['log_AVG_PREP_VID_TIME']\n",
    "chef_model['NUMN_CLASS_PER_PREP_TIME'] = chef_model['log_MASTER_CLASSES_ATTENDED'] / chef_model['log_AVG_PREP_VID_TIME']\n",
    "\n",
    "# average number of orders per time/visit\n",
    "chef_var['AVG_NUMBR_OR_PER_TIME_VISIT'] = chef_var['log_AVG_MEALS_ORDERED'] / chef_var['log_AVG_TIME_PER_SITE_VISIT']\n",
    "chef_model['AVG_NUMBR_OR_PER_TIME_VISIT'] = chef_model['log_AVG_MEALS_ORDERED'] / chef_model['log_AVG_TIME_PER_SITE_VISIT']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Standardize the data</h3><br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# INSTANTIATING a StandardScaler() object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "# FITTING the scaler with the data\n",
    "scaler.fit(chef_var)\n",
    "\n",
    "\n",
    "# TRANSFORMING our data after fit\n",
    "X_scaled = scaler.transform(chef_var)\n",
    "\n",
    "\n",
    "# converting scaled data into a DataFrame\n",
    "X_scaled_df = pd.DataFrame(X_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# adding labels to the scaled DataFrame\n",
    "X_scaled_df.columns = chef_var.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Combination of Features</h3><br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Create combination of features \n",
    "\n",
    "interaction_list = ['log_AVG_TIME_PER_SITE_VISIT',\n",
    "'log_WEEKLY_PLAN',\n",
    "'log_CONTACTS_W_CUSTOMER_SERVICE',\n",
    "'log_AVG_PREP_VID_TIME',\n",
    "'log_AVG_MEALS_ORDERED',\n",
    "'log_AVG_CLICKS_PER_VISIT',\n",
    "'log_TOTAL_PHOTOS_VIEWED',\n",
    "'log_TOTAL_MEALS_ORDERED',\n",
    "'log_MEDIAN_MEAL_RATING',\n",
    "'log_UNIQUE_MEALS_PURCH',\n",
    "'log_CONTACTS_W_CUSTOMER_SERVICE',\n",
    "'log_PRODUCT_CATEGORIES_VIEWED',\n",
    "'log_CANCELLATIONS_BEFORE_NOON',\n",
    "'log_CANCELLATIONS_AFTER_NOON',\n",
    "'log_PC_LOGINS',\n",
    "'log_MOBILE_LOGINS',\n",
    "'log_EARLY_DELIVERIES',\n",
    "'log_LATE_DELIVERIES',\n",
    "'log_MASTER_CLASSES_ATTENDED',\n",
    "'PHOTOS_VIEWED_PER_LOGIN',\n",
    "'NUMN_CLASS_PER_PREP_TIME',  \n",
    "'AVG_NUMBR_OR_PER_TIME_VISIT'\n",
    "]\n",
    "\n",
    "interactions = list(combinations(interaction_list, 2))\n",
    "\n",
    "for interaction in interactions:\n",
    "    chef_var['{}_{}'.format(interaction_list[0], interaction[1])] = chef_var[interaction[0]]* chef_var[interaction[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've added quite a few new features, let's see how they impact our model. Adding a variety of interactions between variables is likely to increase the score of the models. I used the method discussed in this [article](https://towardsdatascience.com/feature-engineering-combination-polynomial-features-3caa4c77a755) from Towards Data Science\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Split the data into Train/Split</h3><br> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# divide chef dataset into dependent and independent variables\n",
    "X = chef_var\n",
    "y = chef_model['log_REVENUE']\n",
    "\n",
    "# Splitting the chef dataset as 75% training and 25% Testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 219)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Building Predictive Models</h2><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Scikit-Learn Linear Regression</h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "x_variables = ['Personal_Domain', 'Professional_Domain', 'Junk', 'CROSS_SELL_SUCCESS', 'MOBILE_NUMBER', 'TASTES_AND_PREFERENCES', 'PACKAGE_LOCKER', 'REFRIGERATED_LOCKER', 'out_REVENUE', 'out_TOTAL_MEALS_ORDERED', 'out_UNIQUE_MEALS_PURCH', 'out_CONTACTS_W_CUSTOMER_SERVICE', 'out_AVG_TIME_PER_SITE_VISIT', 'out_CANCELLATIONS_BEFORE_NOON', 'out_CANCELLATIONS_AFTER_NOON', 'out_EARLY_DELIVERIES', 'out_LATE_DELIVERIES', 'out_AVG_PREP_VID_TIME', 'out_AVG_MEALS_ORDERED', 'out_MASTER_CLASSES_ATTENDED', 'out_AVG_CLICKS_PER_VISIT', 'out_TOTAL_PHOTOS_VIEWED', 'log_AVG_TIME_PER_SITE_VISIT', 'log_WEEKLY_PLAN', 'log_AVG_PREP_VID_TIME', 'log_AVG_MEALS_ORDERED', 'log_AVG_CLICKS_PER_VISIT', 'log_TOTAL_PHOTOS_VIEWED', 'log_TOTAL_MEALS_ORDERED', 'log_MEDIAN_MEAL_RATING', 'log_UNIQUE_MEALS_PURCH', 'log_CONTACTS_W_CUSTOMER_SERVICE', 'log_PRODUCT_CATEGORIES_VIEWED', 'log_CANCELLATIONS_BEFORE_NOON', 'log_CANCELLATIONS_AFTER_NOON', 'log_PC_LOGINS', 'log_MOBILE_LOGINS', 'log_EARLY_DELIVERIES', 'log_LATE_DELIVERIES',\n",
    "       'log_MASTER_CLASSES_ATTENDED', 'VIEWED_PHOTOS', 'PHOTOS_VIEWED_PER_LOGIN', 'NUMN_CLASS_PER_PREP_TIME', 'AVG_NUMBR_OR_PER_TIME_VISIT']\n",
    "\n",
    "# applying scikit-learn\n",
    "\n",
    "# preparing x-variables from the OLS model\n",
    "ols_data = chef_model[x_variables]\n",
    "\n",
    "\n",
    "# preparing response variable\n",
    "chef_target = chef_model['log_REVENUE']\n",
    "\n",
    "\n",
    "###############################################\n",
    "## setting up more than one train-test split ##\n",
    "###############################################\n",
    "# FULL X-dataset (normal Y)\n",
    "x_train_FULL, x_test_FULL, y_train_FULL, y_test_FULL = train_test_split(\n",
    "            chef_var,     # x-variables\n",
    "            chef_target,   # y-variable\n",
    "            test_size = 0.25,\n",
    "            random_state = 219)\n",
    "\n",
    "\n",
    "# OLS p-value x-dataset (normal Y)\n",
    "x_train_OLS, x_test_OLS, y_train_OLS, y_test_OLS = train_test_split(\n",
    "            ols_data,         # x-variables\n",
    "            chef_target,   # y-variable\n",
    "            test_size = 0.25,\n",
    "            random_state = 219)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS Training Score : 0.7473\n",
      "OLS Testing Score  : 0.7328\n",
      "OLS Train-Test Gap : 0.0145\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING a model object\n",
    "lr = LinearRegression()\n",
    "\n",
    "\n",
    "# FITTING to the training data\n",
    "lr_fit = lr.fit(x_train_OLS, y_train_OLS)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "lr_pred = lr_fit.predict(x_test_OLS)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('OLS Training Score :', lr.score(x_train_OLS, y_train_OLS).round(4))  # using R-square\n",
    "print('OLS Testing Score  :',  lr.score(x_test_OLS, y_test_OLS).round(4)) # using R-square\n",
    "\n",
    "lr_train_score = lr.score(x_train_OLS, y_train_OLS).round(4)\n",
    "lr_test_score  = lr.score(x_test_OLS, y_test_OLS).round(4)\n",
    "\n",
    "# displaying and saving the gap between training and testing\n",
    "print('OLS Train-Test Gap :', abs(lr_train_score - lr_test_score).round(4))\n",
    "lr_test_gap = abs(lr_train_score - lr_test_score).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# zipping each feature name to its coefficient\n",
    "lr_model_values = zip(chef_var[x_variables].columns,\n",
    "                      lr_fit.coef_.round(decimals = 2))\n",
    "\n",
    "\n",
    "# setting up a placeholder list to store model features\n",
    "lr_model_lst = [('intercept', lr_fit.intercept_.round(decimals = 2))]\n",
    "\n",
    "\n",
    "# printing out each feature-coefficient pair one by one\n",
    "for val in lr_model_values:\n",
    "    lr_model_lst.append(val)\n",
    "    \n",
    "\n",
    "# checking the results\n",
    "#for pair in lr_model_lst:\n",
    "#    print(pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Lasso Regression</h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Training Score : 0.7459\n",
      "Lasso Testing Score  : 0.7323\n",
      "Lasso Train-Test Gap : 0.0145\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING a model object\n",
    "lasso_model = sklearn.linear_model.Lasso(alpha = .0001,\n",
    "                                         normalize = True) # default magitude\n",
    "\n",
    "\n",
    "# FITTING to the training data\n",
    "lasso_fit = lasso_model.fit(x_train_FULL, y_train_FULL)\n",
    "\n",
    "# PREDICTING on new data\n",
    "lasso_pred = lasso_fit.predict(x_test_FULL)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Lasso Training Score :', lasso_model.score(x_train_FULL, y_train_FULL).round(4))\n",
    "print('Lasso Testing Score  :', lasso_model.score(x_test_FULL, y_test_FULL).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "lasso_train_score = lasso_model.score(x_train_FULL, y_train_FULL).round(4) # using R-square\n",
    "lasso_test_score  = lasso_model.score(x_test_FULL, y_test_FULL).round(4)   # using R-square\n",
    "\n",
    "\n",
    "# displaying and saving the gap between training and testing\n",
    "print('Lasso Train-Test Gap :', abs(lr_train_score - lr_test_score).round(4))\n",
    "lasso_test_gap = abs(lr_train_score - lr_test_score).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# zipping each feature name to its coefficient\n",
    "lasso_model_values = zip(chef_var.columns, lasso_fit.coef_.round(decimals = 2))\n",
    "\n",
    "\n",
    "# setting up a placeholder list to store model features\n",
    "lasso_model_lst = [('intercept', lasso_fit.intercept_.round(decimals = 2))]\n",
    "\n",
    "\n",
    "# printing out each feature-coefficient pair one by one\n",
    "for val in lasso_model_values:\n",
    "    lasso_model_lst.append(val)\n",
    "    \n",
    "\n",
    "# checking the results\n",
    "#for pair in lasso_model_lst:\n",
    "#    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "## This code may have to be run more than once ##\n",
    "\n",
    "# dropping coefficients that are equal to zero\n",
    "\n",
    "# printing out each feature-coefficient pair one by one\n",
    "for feature, coefficient in lasso_model_lst:\n",
    "        \n",
    "        if coefficient == 0:\n",
    "            lasso_model_lst.remove((feature, coefficient))\n",
    "\n",
    "            \n",
    "# checking the results\n",
    "#for pair in lasso_model_lst:\n",
    "#    print(pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>ARD Model</h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7595\n",
      "Testing Score : 0.7517\n",
      "ARD Train-Test Gap : 0.0078\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING a model object\n",
    "ard_model = sklearn.linear_model.ARDRegression(normalize  = False)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "ard_fit = ard_model.fit(x_train_FULL, y_train_FULL)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "ard_pred = ard_fit.predict(x_test_FULL)\n",
    "\n",
    "\n",
    "print('Training Score:', ard_model.score(x_train_FULL, y_train_FULL).round(4))\n",
    "print('Testing Score :',  ard_model.score(x_test_FULL, y_test_FULL).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "ard_train_score = ard_model.score(x_train_FULL, y_train_FULL).round(4)\n",
    "ard_test_score  = ard_model.score(x_test_FULL, y_test_FULL).round(4)\n",
    "\n",
    "\n",
    "# displaying and saving the gap between training and testing\n",
    "print('ARD Train-Test Gap :', abs(ard_train_score - ard_test_score).round(4))\n",
    "ard_test_gap = abs(ard_train_score - ard_test_score).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# zipping each feature name to its coefficient\n",
    "ard_model_values = zip(chef_var.columns, ard_fit.coef_.round(decimals = 5))\n",
    "\n",
    "\n",
    "# setting up a placeholder list to store model features\n",
    "ard_model_lst = [('intercept', ard_fit.intercept_.round(decimals = 2))]\n",
    "\n",
    "\n",
    "# printing out each feature-coefficient pair one by one\n",
    "for val in ard_model_values:\n",
    "    ard_model_lst.append(val)\n",
    "    \n",
    "\n",
    "# checking the results\n",
    "#for pair in ard_model_lst:\n",
    "#    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "## This code may have to be run more than once ##\n",
    "\n",
    "# dropping coefficients that are equal to zero\n",
    "\n",
    "# printing out each feature-coefficient pair one by one\n",
    "for feature, coefficient in ard_model_lst:\n",
    "        \n",
    "        if coefficient == 0:\n",
    "            ard_model_lst.remove((feature, coefficient))\n",
    "\n",
    "            \n",
    "# checking the results\n",
    "#for pair in ard_model_lst:\n",
    "#    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# this is the exact code we were using before\n",
    "X_train_STAND, X_test_STAND, y_train_STAND, y_test_STAND = train_test_split(\n",
    "            X_scaled_df,\n",
    "            chef_target,\n",
    "            test_size = 0.25,\n",
    "            random_state = 219)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>KNN Optimal number of Neighbors</h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal number of neighbors is 14\n"
     ]
    }
   ],
   "source": [
    "# creating lists for training set accuracy and test set accuracy\n",
    "training_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "\n",
    "# building a visualization of 1 to 50 neighbors\n",
    "#neighbors_settings = range(1, 21)\n",
    "\n",
    "\n",
    "#for n_neighbors in neighbors_settings:\n",
    "    #Building the model\n",
    "#    clf = KNeighborsRegressor(n_neighbors = n_neighbors)\n",
    "#    clf.fit(X_train_STAND, y_train_STAND)\n",
    "    \n",
    "    #Recording the training set accuracy\n",
    "#    training_accuracy.append(clf.score(X_train_STAND, y_train_STAND))\n",
    "    \n",
    "    #Recording the generalization accuracy\n",
    "#    test_accuracy.append(clf.score(X_test_STAND, y_test_STAND))\n",
    "\n",
    "\n",
    "# plotting the visualization\n",
    "#fig, ax = plt.subplots(figsize=(12,8))\n",
    "#plt.plot(neighbors_settings, training_accuracy, label = \"training accuracy\")\n",
    "#plt.plot(neighbors_settings, test_accuracy,     label = \"test accuracy\")\n",
    "#plt.ylabel(\"Accuracy\")\n",
    "#plt.xlabel(\"n_neighbors\")\n",
    "#plt.legend()\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "# finding the optimal number of neighbors\n",
    "#opt_neighbors = test_accuracy.index(max(test_accuracy)) + 1\n",
    "#print(f\"\"\"The optimal number of neighbors is {opt_neighbors}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created a visualization from 1 to 50 neighbors to see which value would be optimal. Based on the graph and the output the optimal value is 14."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>KNN Model</h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Training Score: 0.6986\n",
      "KNN Testing Score : 0.6247\n",
      "KNN Train-Test Gap: 0.0739\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING a model with the optimal number of neighbors\n",
    "knn_stand = KNeighborsRegressor(algorithm = 'auto',\n",
    "                                n_neighbors = 14)\n",
    "\n",
    "\n",
    "\n",
    "# FITTING the model based on the training data\n",
    "knn_stand_fit = knn_stand.fit(X_train_STAND, y_train_STAND)\n",
    "\n",
    "\n",
    "\n",
    "# PREDITCING on new data\n",
    "knn_stand_pred = knn_stand_fit.predict(X_test_STAND)\n",
    "\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('KNN Training Score:', knn_stand.score(X_train_STAND, y_train_STAND).round(4))\n",
    "print('KNN Testing Score :',  knn_stand.score(X_test_STAND, y_test_STAND).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "knn_stand_score_train = knn_stand.score(X_train_STAND, y_train_STAND).round(4)\n",
    "knn_stand_score_test  = knn_stand.score(X_test_STAND, y_test_STAND).round(4)\n",
    "\n",
    "\n",
    "# displaying and saving the gap between training and testing\n",
    "print('KNN Train-Test Gap:', abs(knn_stand_score_train - knn_stand_score_test).round(4))\n",
    "knn_stand_test_gap = abs(knn_stand_score_train - knn_stand_score_test).round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN was the model that performed the lowest. It might be interesting to see how well it performs on non-scaled data. We might have a surprise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance = {\n",
    "    \n",
    "    'Model Type'    : ['OLS', 'Lasso', 'ARD', 'KNN'],\n",
    "           \n",
    "    'Training' : [lr_train_score, lasso_train_score,\n",
    "                                   ard_train_score, knn_stand_score_train],\n",
    "           \n",
    "    'Testing'  : [lr_test_score, lasso_test_score,\n",
    "                                   ard_test_score, knn_stand_score_test ],\n",
    "                    \n",
    "    'Train-Test Gap' : [lr_test_gap, lasso_test_gap,\n",
    "                                        ard_test_gap, knn_stand_test_gap],\n",
    "                    \n",
    "    'Model Size' : [len(lr_model_lst), len(lasso_model_lst),\n",
    "                                    len(ard_model_lst), 64],\n",
    "                    \n",
    "    'Model' : [lr_model_lst, lasso_model_lst, ard_model_lst, 'NA' ]}\n",
    "\n",
    "\n",
    "# converting model_performance into a DataFrame\n",
    "model_performance = pd.DataFrame(model_performance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model Type  Training  Testing  Train-Test Gap  Model Size                                              Model\n",
      "0        OLS    0.7473   0.7328          0.0145          45  [(intercept, 4.93), (Personal_Domain, 0.02), (...\n",
      "1      Lasso    0.7459   0.7323          0.0145          39  [(intercept, 4.74), (Personal_Domain, 0.01), (...\n",
      "2        ARD    0.7595   0.7517          0.0078          47  [(intercept, 8.88), (Personal_Domain, 0.01088)...\n",
      "3        KNN    0.6986   0.6247          0.0739          64                                                 NA\n"
     ]
    }
   ],
   "source": [
    "print(model_performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model whith th highest score is the ARD and it has a very small train-test gap.\n",
    "The ARD model in this case  explains more than 75% of the variability of the response data around its mean. The ARD model should be used to predict how much revenue Apprentice Chef should expect from each customer within their first year of using the services.\n",
    "0.75 is a good score for a model and I'm happy with the result."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
